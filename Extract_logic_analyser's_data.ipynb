{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORmWbial9xqe29pLlu+ir3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tony-wade/Reverse-Engineering/blob/main/Extract_logic_analyser's_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recommandation\n",
        "A better logic analyzer (higher sampling rate and fine software) can greatly help your work."
      ],
      "metadata": {
        "id": "Yoj6U_uqoTJ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zivnF8AJ9WjH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import pandas as pd\n",
        "import openpyxl\n",
        "# deque適合只操作首末元素時用\n",
        "# from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_byte(bin_data):\n",
        "    \"\"\"\n",
        "    Convert binary data to hexadecimal format.(不成8的末位會補0)\n",
        "    ['0','0'...] or ['0...',..] --> ['0x??',..] -> ['??',..]\n",
        "    \"\"\"\n",
        "    bin_str = ''.join(list(bin_data))\n",
        "    bits_list = [bin_str[i:i+8].ljust(8, '0') for i in range(0, len(bin_str), 8)]\n",
        "    return [hex(int(bits, 2))[2:].zfill(2) for bits in bits_list]\n",
        "\n",
        "\n",
        "def convert_to_binary(row_data, pkt_len=None, mode=None):\n",
        "    \"\"\"\n",
        "    Convert data to binary form\n",
        "    mode = input type: 'SPI', 'BIN'. Turn hex to binary if not given\n",
        "\n",
        "    \"\"\"\n",
        "    if mode == 'SPI':\n",
        "        # decimal: ['1',... -> [0b1,..-> ['00000001',...], MSB first\n",
        "        int_data = [int(number) for number in row_data if number]\n",
        "        return [bin(num)[2:].zfill(8) for num in int_data]\n",
        "\n",
        "    elif mode == 'BIN' and row_data in ['3', '2']:\n",
        "        # Extract numbers(len). Returns re.Match object if found, else None.\n",
        "        search = re.match(r'(\\d+)', pkt_len) if pkt_len else ValueError('pkt_len is not given')\n",
        "        # Filter noise.\n",
        "        if search:\n",
        "            pkt_length = int(search.group(1))\n",
        "            return generate_bit(row_data) if pkt_length >= 200 else None\n",
        "\n",
        "    else:\n",
        "        # ['0a',..] -> ['0000...',...] -> ['0','0',...]\n",
        "        int_data = [int(hex_num, 16) for hex_num in row_data if pd.notna(hex_num)]\n",
        "        binary_list = [bin(num)[2:].zfill(8) for num in int_data]\n",
        "        return [char for binary_string in binary_list for char in binary_string]"
      ],
      "metadata": {
        "id": "RQlZAvo6z8dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSVs 2 excel"
      ],
      "metadata": {
        "id": "jY44QYNOzqLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv(file_path, mode):\n",
        "    with open(file_path, 'r') as file:\n",
        "        csv_reader = csv.reader(file, delimiter=',')\n",
        "        next(csv_reader)  # 跳過標題行\n",
        "        if mode == 'SPI':\n",
        "            # 取出偶數行中的Decimal data，並去除空字符串或無效的數字字符串\n",
        "            return [\n",
        "                ([x for x in row[3:] if x.strip() and x.strip().isdigit()], None)\n",
        "                for row_idx, row in enumerate(csv_reader)\n",
        "                if row_idx % 2 == 0\n",
        "            ]\n",
        "        elif mode == 'BIN':\n",
        "            # 提取Data, pkt_len，並去除空字符串或無效的數字字符串\n",
        "            return [\n",
        "                (row[3].strip(), row[4].strip())\n",
        "                for row in csv_reader\n",
        "                if row[3].strip().isdigit() and row[4].strip().isdigit()\n",
        "            ]\n",
        "\n",
        "\n",
        "def read_all_csv_files(folder_path, mode):\n",
        "    all_datas = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            datas = read_csv(file_path, mode)\n",
        "            all_datas.extend(datas)   # 將元素加到末尾(不含[])\n",
        "    return all_datas\n",
        "\n",
        "\n",
        "def sequence_to_set(sequences):\n",
        "    if sequences is None:\n",
        "        return None, None\n",
        "\n",
        "    # 資料與長度各設為一個set\n",
        "    length_set = {len(seq) for seq in sequences}\n",
        "    sequence_set = set(sequences)\n",
        "\n",
        "    return sequence_set,  length_set\n",
        "\n",
        "\n",
        "def generate_bit(Data):\n",
        "    # 資料判讀\n",
        "    if Data == '3':\n",
        "        return '1'\n",
        "    elif Data == '2':\n",
        "        return '0'\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def matching(sub_q, data_set, len_set, worksheet):\n",
        "    \"\"\"\n",
        "    Match subsequence with data set.\n",
        "\n",
        "    Args:\n",
        "        sub_q (list): The subsequence to match.\n",
        "        data_set (set): The set to compare with.\n",
        "        len_set (list): List of lengths to check for matching.\n",
        "        worksheet (list): List to append matched sequences.\n",
        "        bin_list (list): List to append binary sequences.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    if data_set is None:\n",
        "        raise ValueError('Sequence is not given')\n",
        "\n",
        "    elif len(sub_q) >= min(len_set):\n",
        "        for length in len_set:\n",
        "            sub_seq = ''.join(sub_q[-length:])\n",
        "            if sub_seq in data_set:\n",
        "                data_q = sub_q[:-length]\n",
        "                worksheet.append(to_byte(data_q))\n",
        "                sub_q.clear()\n",
        "\n",
        "\n",
        "def process_data(datas, mode, start_end_seq=None):\n",
        "    sub_queue = []\n",
        "\n",
        "    # 以set查找\n",
        "    seq_set, seq_len = sequence_to_set(start_end_seq)\n",
        "\n",
        "    # 啟用Excel\n",
        "    workbook = openpyxl.Workbook()\n",
        "    worksheet = workbook.active\n",
        "\n",
        "    if start_end_seq:\n",
        "        for data, pkt_len in datas:\n",
        "            bin_datas = convert_to_binary(data, pkt_len, mode)\n",
        "            for data in bin_datas:\n",
        "                sub_queue.extend(data)\n",
        "                matching(sub_queue,\n",
        "                         seq_set,\n",
        "                         seq_len,\n",
        "                         worksheet)\n",
        "            sub_queue.clear()\n",
        "\n",
        "    else:\n",
        "        if mode=='SPI':\n",
        "            for data, pkt_len in datas:\n",
        "                # SPI下的data為一list   有誤\n",
        "                hex_datas = [\n",
        "                    hex(int(dec_data.strip()))[2:].zfill(2)\n",
        "                    for dec_data in data\n",
        "                ]\n",
        "                worksheet.append(hex_datas)\n",
        "        elif mode=='BIN':\n",
        "            for data, pkt_len in datas:\n",
        "                bin_datas = convert_to_binary(data, pkt_len, mode)\n",
        "                worksheet.append(to_byte(bin_datas))\n",
        "        else:\n",
        "            raise ValueError('Invalid mode')\n",
        "\n",
        "\n",
        "    # 儲存 Excel, 注意不成行序列\n",
        "    workbook.save('output.xlsx')"
      ],
      "metadata": {
        "id": "xgMFHuXQEiS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 讀取CSV,輸出excel\n",
        "input_folder = '.'\n",
        "data = read_all_csv_files(input_folder, 'SPI')\n",
        "process_data(datas=data, mode='SPI')"
      ],
      "metadata": {
        "id": "-FbA886hEiXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Excel extraction"
      ],
      "metadata": {
        "id": "-kncf7Z8zlGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def num_unique_values(col):\n",
        "    \"\"\"\n",
        "    Returns the number of unique non-space values in a pd.Series or DataFrame column.\n",
        "    \"\"\"\n",
        "    return col.nunique(axis=1)\n",
        "\n",
        "\n",
        "def extract_binary_row_data(row_data, filter=None, param=None):\n",
        "    \"\"\"\n",
        "    Extract desired sequences from binary row data based on different filters and parameters.\n",
        "\n",
        "    Parameters:\n",
        "    row_data (list): List of binary data to be processed.\n",
        "    filter (str, optional): The type of filter to apply ('target_str', 'excess_bits', 'analyze_protocol'). Default is None.\n",
        "    param (optional): Parameter for the chosen filter. If filter is 'target_str', it should be a string.\n",
        "                      If filter is 'excess_bits' or 'analyze_protocol', it should be a tuple (length of sequence, [undesired bit positions in the sequence]).\n",
        "\n",
        "    Returns:\n",
        "    list: A list of processed data according to the specified filter and parameter.\n",
        "    \"\"\"\n",
        "    # concate pd.series to a str\n",
        "    valid_data = [str(data) for data in row_data if data]\n",
        "    data_str = ''.join(valid_data)\n",
        "\n",
        "    if filter is None:\n",
        "        return [to_byte(data_str)]\n",
        "\n",
        "    elif param is None:\n",
        "        raise ValueError('param is not given')\n",
        "\n",
        "    elif filter == 'target_str':\n",
        "        # 以開頭做區分\n",
        "        #if data_str.startswith(param):\n",
        "        #   return [to_byte(data_str)]\n",
        "        # 找特定行\n",
        "        return [to_byte(data_str)] if param in data_str else None\n",
        "        # 只輸出指定序列後的資料\n",
        "        #pattern = re.compile(f'{param}(.*?)(?={param}|$)')\n",
        "        #data_list = pattern.findall(data_str)  # 削去指定序列後留下'',沒找到會=[]\n",
        "        #return [to_byte(data) for data in data_list if data]\n",
        "\n",
        "    elif filter == 'excess_bits':\n",
        "        # 去除多餘的bits,不影響排序\n",
        "        length, remove_positions = param\n",
        "        data_chunks = [data_str[i:i+length] for i in range(0, len(data_str), length)]\n",
        "        filtered_chunks = [\n",
        "            ''.join(char for i, char in enumerate(chunk) if i not in remove_positions)\n",
        "            for chunk in data_chunks\n",
        "        ]\n",
        "        return [to_byte(''.join(filtered_chunks))]\n",
        "\n",
        "    elif filter == 'analyze_protocol':\n",
        "        # 去除多餘的bits, 按照指定長度排序\n",
        "        length, remove_positions = param\n",
        "        data_chunks = [data_str[i:i+length] for i in range(0, len(data_str), length)]\n",
        "        filtered_chunks = [\n",
        "            ''.join(char for i, char in enumerate(chunk) if i not in remove_positions)\n",
        "            for chunk in data_chunks\n",
        "        ]\n",
        "        return [[filtered_str[:4]] + to_byte(filtered_str[4:]) for filtered_str in filtered_chunks]\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise ValueError('Invalid filter')\n",
        "\n",
        "\n",
        "\n",
        "def extract_from_xlsx(input_folder, output_file, mode=None, filter=None, param=None):\n",
        "  \"\"\"\n",
        "  Extract row data from an input Excel file to an output Excel file.\n",
        "  \"\"\"\n",
        "  for filename in os.listdir(input_folder):\n",
        "      if filename.endswith(\".xlsx\"):\n",
        "          file_path = os.path.join(input_folder, filename)\n",
        "          print(\"Opening file:\", file_path)\n",
        "\n",
        "          # Read the Excel file into a DataFrame with binary form\n",
        "          df = pd.read_excel(file_path, header=None, dtype=str)\n",
        "          df = pd.DataFrame(convert_to_binary(row) for _, row in df.iterrows())\n",
        "\n",
        "          # clear same data if needed\n",
        "          if mode == 'clear_same_column':\n",
        "              unique_counts = df.nunique()\n",
        "              cols_to_keep = unique_counts[unique_counts > 1].index\n",
        "              df = df[cols_to_keep]\n",
        "              df.columns = range(df.shape[1])\n",
        "\n",
        "          # Extract binary data from each row\n",
        "          extracted_hex_data =[]\n",
        "          for _, row in df.iterrows():\n",
        "              extracted_bin_data = extract_binary_row_data(row, filter, param)\n",
        "              # print(extracted_bin_data) if extracted_bin_data else None\n",
        "              extracted_hex_data.extend(extracted_bin_data) if extracted_bin_data else None\n",
        "\n",
        "\n",
        "          # Create a new DataFrame with the extracted data\n",
        "          df_extracted = pd.DataFrame(extracted_hex_data)\n",
        "\n",
        "          # Save the new DataFrame to an Excel file\n",
        "          df_extracted.to_excel(output_file, index=False, header=False)\n"
      ],
      "metadata": {
        "id": "IuqpqCCHfNXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 要去除的binary通訊協定之stop-start\n",
        "excess_position = (41,[0,5,40])\n",
        "\n",
        "# 目標序列，篩出之後的資料\n",
        "target_sequence = '0000000000000000'\n",
        "\n",
        "# 指定檔案位置，初始為當下位置\n",
        "input_folder = '.'"
      ],
      "metadata": {
        "id": "BgQHpHrpRtUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 篩出excel資料\n",
        "extract_from_xlsx(input_folder=input_folder,\n",
        "                  output_file='258_0000.xlsx',\n",
        "                  #mode='clear_same_column',\n",
        "                  filter='target_str',\n",
        "                  param=target_sequence\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hRjABbS-A-4",
        "outputId": "f0012305-928f-4aa1-9a28-fe2b2451f572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening file: ./258pure.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新增功能"
      ],
      "metadata": {
        "id": "KwL7lJRYrbvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 臨時要讀新的LA, 並分析protocol\n",
        "# 設格式為 (time, scl, sda)\n",
        "def read_csv(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        csv_reader = csv.reader(file, delimiter=',')\n",
        "        next(csv_reader)  # 跳過標題行\n",
        "        next(csv_reader)  # 跳過0s\n",
        "        return [\n",
        "                (float(row[0].strip()), row[2].strip(), row[1].strip())\n",
        "                for row in csv_reader\n",
        "                if len(row) >= 3 and row[2].strip().isdigit() and row[1].strip().isdigit()\n",
        "            ]\n",
        "\n",
        "def read_all_csv_files(folder_path):\n",
        "    all_datas = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            datas = read_csv(file_path)\n",
        "            all_datas.extend(datas)   # 將元素加到末尾(不含[])\n",
        "    return all_datas\n",
        "\n",
        "\n",
        "# CSV to protocol form\n",
        "def process_data(datas):\n",
        "    bin_datas = []\n",
        "    pre_scl = None\n",
        "    prev_time = 0\n",
        "    worksheet = []\n",
        "\n",
        "    for (time, scl, sda) in datas:\n",
        "        if scl == '1' and time - prev_time >= 0.0000007 and pre_scl != '1':\n",
        "            # 一旦有值更改就會被輸出，因此以週期作區分且設為正緣觸發\n",
        "            if time - prev_time > 0.005:\n",
        "                # 長於5ms則視為不同輸入\n",
        "                bin_str = ''.join(bin_datas)\n",
        "                byte_data = extract_binary_row_data(bin_str, 'analyze_protocol', (41,[0,5,40]))\n",
        "                worksheet.extend(byte_data)\n",
        "                bin_datas = []  # 清空 bin_datas\n",
        "            bin_datas.extend(sda)\n",
        "            prev_time = time\n",
        "\n",
        "        pre_scl = scl  # 使中央stop-start影響降至1 bit\n",
        "\n",
        "\n",
        "\n",
        "    bin_str = ''.join(bin_datas)\n",
        "    byte_data = extract_binary_row_data(bin_str, 'analyze_protocol', (41,[0,5,40]))\n",
        "    worksheet.extend(byte_data)\n",
        "    workbook = pd.DataFrame(worksheet)\n",
        "    workbook.to_excel('老三258_test.xlsx', index=False, header=False)\n",
        "\n",
        "\n",
        "\n",
        "input_folder ='.'\n",
        "\n",
        "process_data(read_all_csv_files(input_folder))"
      ],
      "metadata": {
        "id": "pILdD4QXJAQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  臨時直接以首行做分類用\n",
        "def seperate_from_firstline(input_folder, output_file):\n",
        "  \"\"\"\n",
        "  Extract row data from an input Excel file to an output Excel file.\n",
        "  \"\"\"\n",
        "  for filename in os.listdir(input_folder):\n",
        "      if filename.endswith(\".xlsx\"):\n",
        "          file_path = os.path.join(input_folder, filename)\n",
        "          print(\"Opening file:\", file_path)\n",
        "\n",
        "          df = pd.read_excel(file_path, header=None, dtype=str)\n",
        "\n",
        "          extracted_hex_data =[]\n",
        "          for _, row in df.iterrows():\n",
        "              if row[0] not in ['0111', '0011', '0110']:   # 'ee'...etc\n",
        "                    extracted_hex_data.append([data for data in row if data])\n",
        "\n",
        "\n",
        "          # Create a new DataFrame with the extracted data\n",
        "          df_extracted = pd.DataFrame(extracted_hex_data)\n",
        "\n",
        "          # Save the new DataFrame to an Excel file\n",
        "          df_extracted.to_excel(output_file, index=False, header=False)\n",
        "\n",
        "\n",
        "seperate_from_firstline(input_folder=input_folder,\n",
        "                  output_file='277_else.xlsx',\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AXSMp2vwPaH",
        "outputId": "98eaa3dc-134b-421d-e3a5-47ca8caad87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening file: ./老三277_test.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 臨時要讀另一個LA的輸出至bin\n",
        "# 輸入格式為 (id, time, data)\n",
        "def read_csv(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        csv_reader = csv.reader(file, delimiter=',')\n",
        "        next(csv_reader)  # 跳過標題行\n",
        "        next(csv_reader)  # 跳過0s\n",
        "        return [\n",
        "                float(row[2].strip()) for row in csv_reader\n",
        "                if len(row) == 3\n",
        "            ]\n",
        "\n",
        "def read_all_csv_files(folder_path):\n",
        "    all_datas = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            datas = read_csv(file_path)\n",
        "            all_datas.extend(datas)   # 將元素加到末尾(不含[])\n",
        "    return all_datas\n",
        "\n",
        "\n",
        "# CSV to protocol form\n",
        "def process_data(datas):\n",
        "    bin_datas = []\n",
        "    pre_scl = None\n",
        "    prev_time = 0\n",
        "    worksheet = []\n",
        "\n",
        "    for (time, scl, sda) in datas:\n",
        "        if scl == '1' and time - prev_time >= 0.0000007 and pre_scl != '1':\n",
        "            # 一旦有值更改就會被輸出，因此以週期作區分且設為正緣觸發\n",
        "            if time - prev_time > 0.005:\n",
        "                # 長於5ms則視為不同輸入\n",
        "                bin_str = ''.join(bin_datas)\n",
        "                byte_data = extract_binary_row_data(bin_str, 'analyze_protocol', (41,[0,5,40]))\n",
        "                worksheet.extend(byte_data)\n",
        "                bin_datas = []  # 清空 bin_datas\n",
        "            bin_datas.extend(sda)\n",
        "            prev_time = time\n",
        "\n",
        "        pre_scl = scl  # 使中央stop-start影響降至1 bit\n",
        "\n",
        "\n",
        "\n",
        "    bin_str = ''.join(bin_datas)\n",
        "    byte_data = extract_binary_row_data(bin_str, 'analyze_protocol', (41,[0,5,40]))\n",
        "    worksheet.extend(byte_data)\n",
        "    workbook = pd.DataFrame(worksheet)\n",
        "    workbook.to_excel('老三258_test.xlsx', index=False, header=False)\n",
        "\n",
        "\n",
        "\n",
        "input_folder ='.'\n",
        "\n",
        "process_data(read_all_csv_files(input_folder))"
      ],
      "metadata": {
        "id": "xPHbTPE2NJlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MCU燒錄淺談\n",
        "能重覆燒錄的分為EEPROM或Flash\n",
        "\n",
        "\n",
        "1.   Flash: 電訊號即可清寫,方便\n",
        "2.   EEPROM(非快閃): 需用強紫外線清除後才能寫入"
      ],
      "metadata": {
        "id": "JGShQgChrFyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "flah在寫入時會需要輸入一對hex code作為起始燒錄的鑰匙,\n",
        "\n",
        "    ex. AA55, A5F1,...\n",
        "    (以instruction為準,因aa/55在電訊號中較不易因noise而產生=少見)\n",
        "\n",
        "今mcu為二線燒錄: clock, data (即不含gnd, vcc), 且訊號起始條件為clock-low/data-high。\n",
        "\n",
        "UART為獨立單向線路做溝通且以事先設定之Baud Rate為通訊速度, 不含clock (或是傳a,5,f,0這類來做auto baud rate)\n",
        "\n",
        "JTAG為4線燒錄; SPI則有3 or 4線"
      ],
      "metadata": {
        "id": "bFPW6rpjXdkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "寫入MCU的C code會轉換成.hex等檔案, 格式如intel hex等。著重在表示燒錄進mcu的各位置,以code運行次序作為排列基準。\n",
        "\n",
        "而轉換成.bin後，則照次序assembly寫入，並且之中還會插入一些資料。"
      ],
      "metadata": {
        "id": "uVc-VYkAEDpR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**注意各logic analyser對於 start-stop在輸出資料的呈現**"
      ],
      "metadata": {
        "id": "b1LFYtsOvjUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 部分8051系列MCU的燒錄準則"
      ],
      "metadata": {
        "id": "cwJGLL29ggPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Silicon Labs: AN127 - C2 Interface\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# LSB first\n",
        "注意: 各指令間的stop-start波型會被分析儀判定為0b01/0b00(可由手冊及分析儀資料推知)，\n",
        "且data write後與data read等待回傳時會有wait插入, 會是00...01\n",
        "\n",
        "\n",
        "0.   純CLK操作(略)\n",
        "1.   addr write: 0b11 0x02  \n",
        "              (FPCTL register)\n",
        "2.   data write: 0b01 0b00 0x02    <->    10 00 01000000 (LSB first)\n",
        "           ''   ''  0x04\n",
        "           ''   ''  0x01\n",
        "           (ins.)(len.)(flash write enable)\n",
        "\n",
        "3.   addr write: 0b11 0xB4\n",
        "              (FPDAT register,因型號而異)\n",
        "4.   data write: 0b01 0b00 0x07\n",
        "           (ins.)(len.)(PI:block write, block size=code length <= 256, 1 block=多個page)\n",
        "\n",
        "InBusy:\n",
        "5.   addr read: 0b10 \"mcu 回傳 8 bits\", 重複確認直到倒數第二位=0\n",
        "OutReady:\n",
        "6.   addr read: 0b10 \"mcu 回傳 8 bits\", 重複確認直到末位=1\n",
        "\n",
        "7.   data read: 0b00 0b00 \"回傳1byte\", 直到=0x0D\n",
        "\n",
        "\n",
        "8.   data write: 0b01 0b00 0x__(code高位)\n",
        "9.   InBusy\n",
        "10.   data write: 0b01 0b00 0x__(code低位)\n",
        "11.   InBusy\n",
        "\n",
        "12.   data write: 0b01 0b00 0x__(code length, 00=1 byte)\n",
        "13.   InBusy\n",
        "\n",
        "14.   data write: 0b01 0b00 0x__(assembly code)\n",
        "15.   InBusy\n",
        "     (重複14.15逐byte寫入直到寫完)\n",
        "\n",
        "16.   OutReady + step 7.\n",
        "```\n"
      ],
      "metadata": {
        "id": "3YyiC9grc_GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   SMBus:\n",
        "\n",
        "屬於類I2C protocol的通訊方式，Silicon Labs下的晶片能以此做二線通信。 Flash燒錄上則是開啟特定register位置後使用MOVX指令做寫入，但不同晶片間開啟差異大。\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# MSB first\n",
        "Ack是由接收端發送的訊號\n",
        "\n",
        "R/W : S |　slave addr　｜ R/W | Ack | Data | Ack | P     or\n",
        " bits: 1     8      1    1    8   1    1\n",
        "\n",
        "                 ...    | Data | Ack | Data | Ack | ....\n"
      ],
      "metadata": {
        "id": "Tr_KfRcmKGUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Atmel(microchip)-AT89LP:\n",
        "\n",
        " 據CTO所言, SPI能藉由自定義reset方式來將燒錄時的線路降至2 (SDA,SCL)。\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# MSB first\n",
        "少數型號不須'55',同時不支援 Write with auto earse\n",
        "\n",
        "Program enable: AA 55 AC 53 '53'\n",
        "                 由slave回傳\n",
        "\n",
        "Write code page:  AA 55 50  addr(h) addr(l) data_bytes\n",
        "            _ _ '70'  _    _     _\n",
        "              with auto earse\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "zCr6AXdOldNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   TK18 - I2C\n",
        "\n",
        "無詳細communication datasheet, 直接與燒錄訊號,反組譯資料做比對\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "與燒錄按鍵時刻做比對，燒錄起始為5a a5\n",
        "\n",
        "flash register addr.應是 0x40, program instruction write 則為 0x50\n",
        "(I2C:7 bits addr.+ write = A0 ACK 05 ACK)\n",
        "\n",
        "似乎固定為page write,一次寫 1 page共 128 bytes\n",
        "\n",
        "訊號顯示是 write[0x40]: 00 F8 0A\n",
        "      stop 長間隔 start = 0b010\n",
        "      write[0x40]: 05 datas...\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "td5Gio6BpxOp"
      }
    }
  ]
}